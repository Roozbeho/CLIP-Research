import clip
import argparse
from linear_probe import LinearProbe
from zero_shot import ZeroShotClassification
from utils.config import Config
from data_loader import prepare_dataloaders
from utils.visualization import visualize
import torch


def main():
    parser = argparse.ArgumentParser(description="CLIP Reserch (Zero-shot & Linear Probe)")
    parser.add_argument("--cuda", action=argparse.BooleanOptionalAction, default=True,
                        help="Use CUDA if available (default: True)")
    parser.add_argument("-mn", "--model-name", type=str, default='ViT-B/16',
                        help="CLIP model name (default: ViT-B/16)")
    parser.add_argument("-b", "--batch-size", type=int, default=500,
                        help="Batch size during evaluation (default: 500)")
    parser.add_argument("-c", "--linear-probe-c", type=float, default=0.316,
                        help="Regularization parameter C for logistic regression (default: 0.316)")
    parser.add_argument("-mi", "--linear-probe-max-iter", type=int, default=1000,
                        help="Maximum iterations for logistic regression (default: 1000)")
    parser.add_argument("-d", "--dataset-root", type=str, default="./data",
                        help="Path to dataset root directory (default: ./data)")
    parser.add_argument("-v", "--visualize", action=argparse.BooleanOptionalAction, default=False,
                        help="Flag for Saving visual report to file (default: False)")
    
    args = parser.parse_args()

    conf_dict = {
        'device': torch.device('cuda' if (torch.cuda.is_available() and args.cuda) else 'cpu'),
        'model_name': args.model_name,
        'batch_size': args.batch_size,
        'linear_probe_c': args.linear_probe_c,
        'linear_probe_max_iter': args.linear_probe_max_iter,
        'dataset_root': args.dataset_root,
        'save_visualization': args.visualize
    }
    config = Config.from_dict(conf_dict)

    clip_model, preprocess = clip.load(config.model_name, device=config.device)
    model_resolution = clip_model.visual.input_resolution

    print("Loading and prepairing data")
    train_loader, test_loader = prepare_dataloaders(config, model_resolution)

    print("="*50)
    print("Evaluating Zero-Shot Performance")
    classes = [
        # Simple digit names
        [str(i) for i in range(10)],
        
        # Descriptive phrases
        [f"a photo of the digit {i}" for i in range(10)],
        [f"an image showing the number {i}" for i in range(10)],
        [f"a handwritten {i}" for i in range(10)],
        
        # More complex descriptions
        [f"this is clearly the number {i}" for i in range(10)],
        [f"the digit displayed is {i}" for i in range(10)],
        
        # Mixed case
        [f"Digit {i}" for i in range(10)],
        [f"NUMBER {i}" for i in range(10)],
    ] # NOTE: this class variations are generated by AI

    zero_shot = ZeroShotClassification(config, clip_model, classes)
    zero_shot_accuracies = zero_shot.evaluate(train_loader)

    print("Zero-Shot accuracies:")
    for i, acc in enumerate(zero_shot_accuracies):
        print(f"(ex: {classes[i][0]}) : {acc:.2f}")

    print("="*50)
    print("Evaluating Linear Probe Performance")
    linear_probe = LinearProbe(config, clip_model)
    linear_probe_accuracies = linear_probe.train_and_evaluate(train_loader, test_loader)

    print(f"Linear Probe accuracies : {linear_probe_accuracies:.2f}")

    if args.visualize:
        print("="*50)
        print("Preparing visualization report")
        visualize(classes, zero_shot_accuracies, linear_probe_accuracies, config.save_visualization)

if __name__ == '__main__':
    main()