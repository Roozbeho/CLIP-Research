import argparse

import clip
import torch

from data_loader import prepare_dataloaders
from linear_probe import LinearProbe
from utils.config import Config
from utils.visualization import visualize
from zero_shot import ZeroShotClassification


def main():
    parser = argparse.ArgumentParser(
        description="CLIP Reserch (Zero-shot & Linear Probe)"
    )
    parser.add_argument(
        "--cuda",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="Use CUDA if available (default: True)",
    )
    parser.add_argument(
        "-mn",
        "--model-name",
        type=str,
        default="ViT-B/16",
        help="CLIP model name (default: ViT-B/16)",
    )
    parser.add_argument(
        "-b",
        "--batch-size",
        type=int,
        default=500,
        help="Batch size during evaluation (default: 500)",
    )
    parser.add_argument(
        "-c",
        "--linear-probe-c",
        type=float,
        default=0.316,
        help="Regularization parameter C for logistic regression (default: 0.316)",
    )
    parser.add_argument(
        "-mi",
        "--linear-probe-max-iter",
        type=int,
        default=1000,
        help="Maximum iterations for logistic regression (default: 1000)",
    )
    parser.add_argument(
        "-d",
        "--dataset-root",
        type=str,
        default="./data",
        help="Path to dataset root directory (default: ./data)",
    )
    parser.add_argument(
        "-v",
        "--visualize",
        action=argparse.BooleanOptionalAction,
        default=False,
        help="Flag for Saving visual report to file (default: False)",
    )

    args = parser.parse_args()

    conf_dict = {
        "device": torch.device(
            "cuda" if (torch.cuda.is_available() and args.cuda) else "cpu"
        ),
        "model_name": args.model_name,
        "batch_size": args.batch_size,
        "linear_probe_c": args.linear_probe_c,
        "linear_probe_max_iter": args.linear_probe_max_iter,
        "dataset_root": args.dataset_root,
        "save_visualization": args.visualize,
    }
    config = Config.from_dict(conf_dict)

    clip_model, preprocess = clip.load(config.model_name, device=config.device)
    model_resolution = clip_model.visual.input_resolution

    print("Loading and prepairing data")
    train_loader, test_loader = prepare_dataloaders(config, model_resolution)

    print("=" * 50)
    print("Evaluating Zero-Shot Performance")
    classes = [
        # Simple digit names
        [str(i) for i in range(10)],
        # Descriptive phrases
        [f"a photo of the digit {i}" for i in range(10)],
        [f"an image showing the number {i}" for i in range(10)],
        [f"a handwritten {i}" for i in range(10)],
        # More complex descriptions
        [f"this is clearly the number {i}" for i in range(10)],
        [f"the digit displayed is {i}" for i in range(10)],
        # Mixed case
        [f"Digit {i}" for i in range(10)],
        [f"NUMBER {i}" for i in range(10)],
    ]  # NOTE: this class variations are generated by AI

    zero_shot = ZeroShotClassification(config, clip_model, classes)
    zero_shot_accuracies = zero_shot.evaluate(train_loader)

    print("Zero-Shot accuracies:")
    for i, acc in enumerate(zero_shot_accuracies):
        print(f"(ex: {classes[i][0]}) : {acc:.2f}")

    print("=" * 50)
    print("Evaluating Linear Probe Performance")
    linear_probe = LinearProbe(config, clip_model)
    linear_probe_accuracies = linear_probe.train_and_evaluate(train_loader, test_loader)

    print(f"Linear Probe accuracies : {linear_probe_accuracies:.2f}")

    if args.visualize:
        print("=" * 50)
        print("Preparing visualization report")
        visualize(
            classes,
            zero_shot_accuracies,
            linear_probe_accuracies,
            config.save_visualization,
        )


if __name__ == "__main__":
    main()
